{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVIDx-CT Dataset Constructor\n",
    "This notebook constructs the COVIDx-CT dataset from scratch using the raw data. See [docs/dataset.md](docs/dataset.md) for more details on manual steps which must be completed beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Paths\n",
    "Paths to the source data and output location should be set here. Note that the window width and window level for processing scans in Hounsfield units are defined in [data_utils.py](data_utils.py) as `HU_WINDOW_WIDTH = 1500` and `HU_WINDOW_LEVEL = -600`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset version. Major version (e.g., v2) should match current release.\n",
    "# Checkout earlier versions of the repo to construct previous dataset versions.\n",
    "DATASET_VERSION = 'v2A'\n",
    "\n",
    "# CNCB AI Diagnosis paths\n",
    "CNCB_EXCLUDE_FILE = 'dataset_construction/metadata/cncb_exclude_list.txt'\n",
    "CNCB_DIR = 'data/CNCB_AIDiagnosis'\n",
    "\n",
    "# Radiopaedia/coronacases segmentation data paths\n",
    "RADIOPAEDIA_CORONACASES_CT_DIR = 'data/Coronacases_Radiopaedia/COVID-19-CT-Seg_20cases'\n",
    "RADIOPAEDIA_CORONACASES_SEG_DIR = 'data/Coronacases_Radiopaedia/Infection_Mask'\n",
    "\n",
    "# LIDC-IDRI paths\n",
    "LIDC_META_CSV = 'dataset_construction/metadata/lidc_idri_metadata.csv'\n",
    "\n",
    "# COVID-19-20 paths\n",
    "COVID_19_20_DIR = 'data/COVID-19-20_v2/Train'\n",
    "\n",
    "# COVID-CTset paths\n",
    "COVID_CTSET_META_CSV = 'data/COVID-CTset/Labels&Detailes/Patient_details.csv'\n",
    "COVID_CTSET_DIR = 'data/COVID-CTset/Train&Validation'\n",
    "\n",
    "# MosMedData paths\n",
    "MOSMED_CT_DIR = 'data/MosMedData/COVID19_1110/studies/CT-1'\n",
    "MOSMED_SEG_DIR = 'data/MosMedData/COVID19_1110/masks'\n",
    "\n",
    "# Extra Radiopaedia data paths\n",
    "RADIOPAEDIA_META_CSV = 'dataset_construction/metadata/radiopaedia_metadata.csv'\n",
    "RADIOPAEDIA_EXCLUDE_FILE = 'dataset_construction/metadata/radiopaedia_exclude_list.txt'\n",
    "\n",
    "# Extra TCIA COVID-19 study paths\n",
    "TCIA_COVID_META_CSV = 'dataset_construction/metadata/tcia_covid_metadata.csv'\n",
    "TCIA_COVID_EXCLUDE_FILE = 'dataset_construction/metadata/tcia_covid_exclude_list.txt'\n",
    "TCIA_DIR = 'data/CT_Images_in_COVID-19_August_2020'\n",
    "\n",
    "# Output directory path\n",
    "OUTPUT_DIR = 'data/COVIDx-CT_{}'.format(DATASET_VERSION)  # directory to save the images in\n",
    "\n",
    "# Make output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "These cells process the data from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename and class lists\n",
    "filenames, classes = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 103981/103981 [00:03<00:00, 26829.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process CNCB AI Diagnosis data\n",
    "from dataset_construction import cncb\n",
    "fnames, cls = cncb.process_cncb_data(CNCB_EXCLUDE_FILE, CNCB_DIR, OUTPUT_DIR)\n",
    "filenames.extend(fnames)\n",
    "classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process radiopaedia and coronacases data\n",
    "from dataset_construction import radiopaedia_coronacases as rc\n",
    "fnames, cls = rc.process_radiopaedia_and_coronacases_seg_data(\n",
    "    RADIOPAEDIA_CORONACASES_CT_DIR, RADIOPAEDIA_CORONACASES_SEG_DIR, OUTPUT_DIR)\n",
    "filenames.extend(fnames)\n",
    "classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:47<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process LIDC-IDRI data\n",
    "from dataset_construction import lidc_idri\n",
    "fnames, cls = lidc_idri.process_lidc_idri_data(LIDC_META_CSV, OUTPUT_DIR)\n",
    "filenames.extend(fnames)\n",
    "classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [03:17<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process COVID-19-20 challenge data\n",
    "from dataset_construction import covid_19_20\n",
    "fnames, cls = covid_19_20.process_covid_19_20_data(COVID_19_20_DIR, OUTPUT_DIR)\n",
    "filenames.extend(fnames)\n",
    "classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 377/377 [00:08<00:00, 45.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process COVID-CTset data\n",
    "from dataset_construction import covid_ctset\n",
    "fnames, cls = covid_ctset.process_covid_ctset_data(COVID_CTSET_META_CSV, COVID_CTSET_DIR, OUTPUT_DIR)\n",
    "filenames.extend(fnames)\n",
    "classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:29<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process MosMedData studies (only for \"B\" variant)\n",
    "if DATASET_VERSION[-1] == 'B':\n",
    "    from dataset_construction import mosmed\n",
    "    fnames, cls = mosmed.process_mosmed_data(MOSMED_CT_DIR, MOSMED_SEG_DIR, OUTPUT_DIR)\n",
    "    filenames.extend(fnames)\n",
    "    classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 118/118 [00:45<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process extra Radiopaedia studies (only for \"B\" variant)\n",
    "if DATASET_VERSION[-1] == 'B':\n",
    "    from dataset_construction import radiopaedia\n",
    "    fnames, cls = radiopaedia.process_radiopaedia_data(RADIOPAEDIA_META_CSV, RADIOPAEDIA_EXCLUDE_FILE, OUTPUT_DIR)\n",
    "    filenames.extend(fnames)\n",
    "    classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 248/248 [03:20<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process extra TCIA COVID-19 studies (only for \"B\" variant)\n",
    "if DATASET_VERSION[-1] == 'B':\n",
    "    from dataset_construction import tcia_covid\n",
    "    fnames, cls = tcia_covid.process_tcia_covid_data(TCIA_COVID_META_CSV, TCIA_COVID_EXCLUDE_FILE, TCIA_DIR, OUTPUT_DIR)\n",
    "    filenames.extend(fnames)\n",
    "    classes.extend(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Counts\n",
      "Normal: [60083]\n",
      "Pneumonia: [38121]\n",
      "COVID-19: [35716]\n"
     ]
    }
   ],
   "source": [
    "# Print image counts\n",
    "from dataset_construction.utils import CLASS_MAP\n",
    "uniq_classes, counts = np.unique(classes, return_counts=True)\n",
    "print('Image Counts')\n",
    "for name, cls in CLASS_MAP.items():\n",
    "    print('{}: {}'.format(name, counts[uniq_classes == cls]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "Perform a check to ensure that all files are present (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133920/133920 files created, dataset successfully constructed!\n"
     ]
    }
   ],
   "source": [
    "# Get split files\n",
    "split_files = glob.glob(os.path.join('splits/' + DATASET_VERSION[:2], '*_COVIDx-CT_{}.txt'.format(DATASET_VERSION)))\n",
    "if not len(split_files):\n",
    "    raise ValueError('Split files for COVIDx-CT {} not found'.format(DATASET_VERSION))\n",
    "\n",
    "# Default to \"A\" variant when \"B\" variant files are not present\n",
    "if len(split_files) != 3:\n",
    "    a_var = DATASET_VERSION[:-1] + 'A'\n",
    "    existing_splits = set(os.path.basename(split_file).split('_')[0] for split_file in split_files)\n",
    "    split_files_a = glob.glob(os.path.join('splits/' + DATASET_VERSION[:2], '*_COVIDx-CT_{}.txt'.format(a_var)))\n",
    "    split_files_a = [f for f in split_files_a if os.path.basename(f).split('_')[0] not in existing_splits]\n",
    "    split_files = split_files + split_files_a\n",
    "\n",
    "# Check that all files from all splits are present in the constructed data\n",
    "count = 0\n",
    "total = 0\n",
    "incomplete = False\n",
    "for split_file in split_files:\n",
    "    with open(split_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            fname, cls = line.strip('\\n').split()[:2]\n",
    "            fpath = os.path.join(OUTPUT_DIR, fname)\n",
    "            \n",
    "            total += 1\n",
    "            if os.path.exists(fpath):\n",
    "                count += 1\n",
    "            else:\n",
    "                print('Missing', fname)\n",
    "                incomplete = True\n",
    "if incomplete:\n",
    "    print('{}/{} files are missing, dataset is incomplete!'.format(count, total))\n",
    "else:\n",
    "    print('{}/{} files created, dataset successfully constructed!'.format(count, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
